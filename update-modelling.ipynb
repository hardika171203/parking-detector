{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H_EGzX24BWfV"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3wTQ83ZpQJc"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFP6GUrtpVsz"
   },
   "source": [
    "# Install Library yang dibutuhkan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\moviepy\\__init__.py\n"
     ]
    }
   ],
   "source": [
    "import moviepy\n",
    "print(moviepy.__file__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3247,
     "status": "ok",
     "timestamp": 1736923277349,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "2p7FhhDsqH-5",
    "outputId": "b0c9850a-0499-4f26-c208-9cc480aa0162"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'moviepy.editor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmoviepy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meditor\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m VideoFileClip\n\u001b[0;32m      7\u001b[0m cwd \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetcwd()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'moviepy.editor'"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os, glob\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "cwd = os.getcwd()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SolmxgkQDvRH"
   },
   "source": [
    "# fungsi show_images:tentukan tata letak, buat figure, tampilkan setiap gambar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQ_9ccAsp0Jf"
   },
   "outputs": [],
   "source": [
    "def show_images(images, cmap=None):\n",
    "    cols = 2 # tentukan tata letak\n",
    "    rows = (len(images)+1)//cols # jumlah baris dihitung berdasarkan jumlah gambar dalam kolom\n",
    "\n",
    "    plt.figure(figsize=(15, 12)) # membuat figure baru\n",
    "    for i, image in enumerate(images): # mengiterasi setiap gambar dalam daftar\n",
    "        plt.subplot(rows, cols, i+1) # membuat subplot untuk setiap gambar\n",
    "        # Gunakan peta warna skala abu-abu jika hanya ada satu saluran\n",
    "        cmap = 'gray' if len(image.shape)==2 else cmap\n",
    "        plt.imshow(image, cmap=cmap)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.tight_layout(pad=0, h_pad=0, w_pad=0)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 295,
     "status": "ok",
     "timestamp": 1736923277353,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "8Kis6xpp6iSH",
    "outputId": "ab428c3a-198e-48ce-aac7-78a1d8b67408"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_images = [plt.imread(path) for path in glob.glob('/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/test_images/*.jpg')]\n",
    "\n",
    "show_images(test_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "op09CmMp2ouL"
   },
   "source": [
    "# Prepocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mOYHP9fB6iSH"
   },
   "source": [
    "## Seleksi Warna (Color Selection)\n",
    "# membuat filter warna\n",
    "# menggabungkan filter\n",
    "# menerapkan filter\n",
    "# mengembalikan gambar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 299,
     "status": "ok",
     "timestamp": 1736923277362,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "kLOKtujf6iSM",
    "outputId": "b038e705-1a95-412d-d842-d294a8d28478"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Dua masker warna dibuat, satu untuk putih dan satu untuk kuning, menggunakan rentang nilai RGB tertentu.\n",
    "# cv2.inRange digunakan untuk membuat masker, piksel dalam rentang warna akan bernilai 1 (putih) dan di luar rentang akan bernilai 0 (hitam).\n",
    "\n",
    "# image is expected be in RGB color space# image\n",
    "def select_rgb_white_yellow(image):\n",
    "    # filter warna putih\n",
    "    lower = np.uint8([120, 120, 120])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    white_mask = cv2.inRange(image, lower, upper)\n",
    "    # filter warna kuning\n",
    "    lower = np.uint8([190, 190,   0])\n",
    "    upper = np.uint8([255, 255, 255])\n",
    "    yellow_mask = cv2.inRange(image, lower, upper)\n",
    "    # menggabungkan filter\n",
    "    # Filter putih dan kuning digabungkan menggunakan cv2.bitwise_or. Hasilnya, piksel yang merupakan warna putih atau kuning akan bernilai 1\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    # Masker yang digabungkan diterapkan pada gambar asli\n",
    "    # Hanya piksel yang bernilai 1 pada filter (warna putih atau kuning) yang akan dipertahankan pada gambar hasil.\n",
    "    masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return masked\n",
    "\n",
    "#Fungsi mengembalikan gambar yang telah difilter, hanya menampilkan area berwarna putih dan kuning\n",
    "white_yellow_images = list(map(select_rgb_white_yellow, test_images))\n",
    "show_images(white_yellow_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gSCUlTB9c-Y-"
   },
   "source": [
    "# Konversi ke Skala Abu-abu (Grayscale Conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 296,
     "status": "ok",
     "timestamp": 1736923277362,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "30m2WpiX6iSN",
    "outputId": "51879e07-1bd7-448d-d9c4-5b64dd0d5acb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def convert_gray_scale(image):\n",
    "    return cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) # konversi warna\n",
    "    # flag yang menunjukkan konversi dari ruang warna RGB (Red, Green, Blue) ke grayscale\n",
    "    # Fungsi ini mengembalikan gambar yang telah dikonversi ke grayscale.\n",
    "\n",
    "#Hasilnya disimpan dalam list baru bernama gray_images, yang berisi gambar-gambar dalam format grayscale.\n",
    "gray_images = list(map(convert_gray_scale, white_yellow_images))\n",
    "\n",
    "# menampilkan gambar-gambar dalam list\n",
    "show_images(gray_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o5uIgC7ndI7O"
   },
   "source": [
    "#  Deteksi Tepi (Edge Detection) Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 120,
     "status": "ok",
     "timestamp": 1736923277363,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "ITMbK3NU6iSN",
    "outputId": "3d098ced-7ae9-4f6f-bc1e-279e0d4a0508"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# OpenCV digunakan untuk mendeteksi tepi pada gambar menggunakan algoritma Canny\n",
    "def detect_edges(image, low_threshold=50, high_threshold=200):\n",
    "    return cv2.Canny(image, low_threshold, high_threshold)\n",
    "\n",
    "edge_images = list(map(lambda image: detect_edges(image), gray_images))\n",
    "\n",
    "show_images(edge_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtCpaAQF6iSN"
   },
   "source": [
    "### identifikasi  Pemilihan Area (Region of Interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 668,
     "status": "ok",
     "timestamp": 1736923277941,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "Lz3kZv4n6iSO",
    "outputId": "ca14ac26-153e-41c2-e15c-bf0e0cb99d9e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def filter_region(image, vertices):\n",
    "    \"\"\"\n",
    "    Create the mask using the vertices and apply it to the input image\n",
    "    \"\"\"\n",
    "    mask = np.zeros_like(image)\n",
    "    if len(mask.shape)==2:\n",
    "        cv2.fillPoly(mask, vertices, 255)\n",
    "    else:\n",
    "        cv2.fillPoly(mask, vertices, (255,)*mask.shape[2]) # in case, the input image has a channel dimension\n",
    "    return cv2.bitwise_and(image, mask)\n",
    "\n",
    "\n",
    "def select_region(image):\n",
    "    \"\"\"\n",
    "    It keeps the region surrounded by the `vertices` (i.e. polygon).  Other area is set to 0 (black).\n",
    "    \"\"\"\n",
    "    # first, define the polygon by vertices\n",
    "    rows, cols = image.shape[:2]\n",
    "    pt_1  = [cols*0.05, rows*0.90]\n",
    "    pt_2 = [cols*0.05, rows*0.70]\n",
    "    pt_3 = [cols*0.30, rows*0.55]\n",
    "    pt_4 = [cols*0.6, rows*0.15]\n",
    "    pt_5 = [cols*0.90, rows*0.15]\n",
    "    pt_6 = [cols*0.90, rows*0.90]\n",
    "    # the vertices are an array of polygons (i.e array of arrays) and the data type must be integer\n",
    "    vertices = np.array([[pt_1, pt_2, pt_3, pt_4, pt_5, pt_6]], dtype=np.int32)\n",
    "    return filter_region(image, vertices)\n",
    "\n",
    "\n",
    "# images showing the region of interest only\n",
    "roi_images = list(map(select_region, edge_images))\n",
    "\n",
    "show_images(roi_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "15nycIbP2hSx"
   },
   "source": [
    "# Ekstrasi Fitur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uJ5iwGgJ6iSO"
   },
   "source": [
    "###  Transformasi Hough Line (Hough Line Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKeVH89v6iSO"
   },
   "outputs": [],
   "source": [
    "def hough_lines(image):\n",
    "    \"\"\"\n",
    "    `image` should be the output of a Canny transform.\n",
    "\n",
    "    Returns hough lines (  the image with lines)\n",
    "    \"\"\"\n",
    "    return cv2.HoughLinesP(image, rho=0.1, theta=np.pi/10, threshold=15, minLineLength=9, maxLineGap=4)\n",
    "\n",
    "\n",
    "list_of_lines = list(map(hough_lines, roi_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "524r-MLDdiFc"
   },
   "source": [
    "# menggambar garis-garis yang terdeteksi oleh Hough Line Transform pada citra asli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 75,
     "status": "ok",
     "timestamp": 1736923277943,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "3LRh2kOK6iSO",
    "outputId": "d1fb6ace-85e9-49e4-aebf-b04ee34966fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_lines(image, lines, color=[255, 0, 0], thickness=2, make_copy=True):\n",
    "    # the lines returned by cv2.HoughLinesP has the shape (-1, 1, 4)\n",
    "    if make_copy:\n",
    "        image = np.copy(image) # don't want to modify the original\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if abs(y2-y1) <=1 and abs(x2-x1) >=25 and abs(x2-x1) <= 55:\n",
    "                cleaned.append((x1,y1,x2,y2))\n",
    "                cv2.line(image, (x1, y1), (x2, y2), color, thickness)\n",
    "    print(\" No lines detected: \", len(cleaned))\n",
    "    return image\n",
    "\n",
    "\n",
    "line_images = []\n",
    "for image, lines in zip(test_images, list_of_lines):\n",
    "    line_images.append(draw_lines(image, lines))\n",
    "\n",
    "show_images(line_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-cOMn1-6iSP"
   },
   "source": [
    "## Identifikasi blok parkir persegi panjang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 74,
     "status": "ok",
     "timestamp": 1736923277944,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "AIIqlg5o6iSP",
    "outputId": "d852a4aa-e558-4a0c-f608-cefcf5060da1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def identify_blocks(image, lines, make_copy=True):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "    #Step 1: Create a clean list of lines\n",
    "    cleaned = []\n",
    "    for line in lines:\n",
    "        for x1,y1,x2,y2 in line:\n",
    "            if abs(y2-y1) <=1 and abs(x2-x1) >=25 and abs(x2-x1) <= 55:\n",
    "                cleaned.append((x1,y1,x2,y2))\n",
    "\n",
    "    #Step 2: Sort cleaned by x1 position\n",
    "    import operator\n",
    "    list1 = sorted(cleaned, key=operator.itemgetter(0, 1))\n",
    "\n",
    "    #Step 3: Find clusters of x1 close together - clust_dist apart\n",
    "    clusters = {}\n",
    "    dIndex = 0\n",
    "    clus_dist = 10\n",
    "\n",
    "    for i in range(len(list1) - 1):\n",
    "        distance = abs(list1[i+1][0] - list1[i][0])\n",
    "    #         print(distance)\n",
    "        if distance <= clus_dist:\n",
    "            if not dIndex in clusters.keys(): clusters[dIndex] = []\n",
    "            clusters[dIndex].append(list1[i])\n",
    "            clusters[dIndex].append(list1[i + 1])\n",
    "\n",
    "        else:\n",
    "            dIndex += 1\n",
    "\n",
    "    #Step 4: Identify coordinates of rectangle around this cluster\n",
    "    rects = {}\n",
    "    i = 0\n",
    "    for key in clusters:\n",
    "        all_list = clusters[key]\n",
    "        cleaned = list(set(all_list))\n",
    "        if len(cleaned) > 5:\n",
    "            cleaned = sorted(cleaned, key=lambda tup: tup[1])\n",
    "            avg_y1 = cleaned[0][1]\n",
    "            avg_y2 = cleaned[-1][1]\n",
    "    #         print(avg_y1, avg_y2)\n",
    "            avg_x1 = 0\n",
    "            avg_x2 = 0\n",
    "            for tup in cleaned:\n",
    "                avg_x1 += tup[0]\n",
    "                avg_x2 += tup[2]\n",
    "            avg_x1 = avg_x1/len(cleaned)\n",
    "            avg_x2 = avg_x2/len(cleaned)\n",
    "            rects[i] = (avg_x1, avg_y1, avg_x2, avg_y2)\n",
    "            i += 1\n",
    "\n",
    "    print(\"Num Parking Lanes: \", len(rects))\n",
    "    #Step 5: Draw the rectangles on the image\n",
    "    buff = 7\n",
    "    for key in rects:\n",
    "        tup_topLeft = (int(rects[key][0] - buff), int(rects[key][1]))\n",
    "        tup_botRight = (int(rects[key][2] + buff), int(rects[key][3]))\n",
    "#         print(tup_topLeft, tup_botRight)\n",
    "        cv2.rectangle(new_image, tup_topLeft,tup_botRight,(0,255,0),3)\n",
    "    return new_image, rects\n",
    "\n",
    "# images showing the region of interest only\n",
    "rect_images = []\n",
    "rect_coords = []\n",
    "for image, lines in zip(test_images, list_of_lines):\n",
    "    new_image, rects = identify_blocks(image, lines)\n",
    "    rect_images.append(new_image)\n",
    "    rect_coords.append(rects)\n",
    "\n",
    "show_images(rect_images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-ORH8q_6iSP"
   },
   "source": [
    "## Identifikasi setiap tempat dan hitung jumlah tempat parkir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-zDK45H6iSP"
   },
   "source": [
    "Langkah selanjutnya-\n",
    "\n",
    "Berdasarkan lebar setiap segmen garis parkir ke tempat individu,\n",
    "Gambar visualisasi semua tempat parkir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1736923277944,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "OkpBw_xz6iSP",
    "outputId": "0ccc1e55-39b5-4721-f198-445b3c614724"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1200 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def draw_parking(image, rects, make_copy = True, color=[255, 0, 0], thickness=2, save = True):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "    gap = 15.5\n",
    "    spot_dict = {} # maps each parking ID to its coords\n",
    "    tot_spots = 0\n",
    "    adj_y1 = {0: 20, 1:-10, 2:0, 3:-11, 4:28, 5:5, 6:-15, 7:-15, 8:-10, 9:-30, 10:9, 11:-32}\n",
    "    adj_y2 = {0: 30, 1: 50, 2:15, 3:10, 4:-15, 5:15, 6:15, 7:-20, 8:15, 9:15, 10:0, 11:30}\n",
    "\n",
    "    adj_x1 = {0: -8, 1:-15, 2:-15, 3:-15, 4:-15, 5:-15, 6:-15, 7:-15, 8:-10, 9:-10, 10:-10, 11:0}\n",
    "    adj_x2 = {0: 0, 1: 15, 2:15, 3:15, 4:15, 5:15, 6:15, 7:15, 8:10, 9:10, 10:10, 11:0}\n",
    "    for key in rects:\n",
    "        # Horizontal lines\n",
    "        tup = rects[key]\n",
    "        x1 = int(tup[0]+ adj_x1[key])\n",
    "        x2 = int(tup[2]+ adj_x2[key])\n",
    "        y1 = int(tup[1] + adj_y1[key])\n",
    "        y2 = int(tup[3] + adj_y2[key])\n",
    "        cv2.rectangle(new_image, (x1, y1),(x2,y2),(0,255,0),2)\n",
    "        num_splits = int(abs(y2-y1)//gap)\n",
    "        for i in range(0, num_splits+1):\n",
    "            y = int(y1 + i*gap)\n",
    "            cv2.line(new_image, (x1, y), (x2, y), color, thickness)\n",
    "        if key > 0 and key < len(rects) -1 :\n",
    "            #draw vertical lines\n",
    "            x = int((x1 + x2)/2)\n",
    "            cv2.line(new_image, (x, y1), (x, y2), color, thickness)\n",
    "        # Add up spots in this lane\n",
    "        if key == 0 or key == (len(rects) -1):\n",
    "            tot_spots += num_splits +1\n",
    "        else:\n",
    "            tot_spots += 2*(num_splits +1)\n",
    "\n",
    "        # Dictionary of spot positions\n",
    "        if key == 0 or key == (len(rects) -1):\n",
    "            for i in range(0, num_splits+1):\n",
    "                cur_len = len(spot_dict)\n",
    "                y = int(y1 + i*gap)\n",
    "                spot_dict[(x1, y, x2, y+gap)] = cur_len +1\n",
    "        else:\n",
    "            for i in range(0, num_splits+1):\n",
    "                cur_len = len(spot_dict)\n",
    "                y = int(y1 + i*gap)\n",
    "                x = int((x1 + x2)/2)\n",
    "                spot_dict[(x1, y, x, y+gap)] = cur_len +1\n",
    "                spot_dict[(x, y, x2, y+gap)] = cur_len +2\n",
    "\n",
    "    print(\"total parking spaces: \", tot_spots, cur_len)\n",
    "    if save:\n",
    "        filename = 'with_parking.jpg'\n",
    "        cv2.imwrite(filename, new_image)\n",
    "    return new_image, spot_dict\n",
    "\n",
    "delineated = []\n",
    "spot_pos = []\n",
    "for image, rects in zip(test_images, rect_coords):\n",
    "    new_image, spot_dict = draw_parking(image, rects)\n",
    "    delineated.append(new_image)\n",
    "    spot_pos.append(spot_dict)\n",
    "\n",
    "show_images(delineated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 70,
     "status": "error",
     "timestamp": 1736923277944,
     "user": {
      "displayName": "MAYRA ANGGRAINI",
      "userId": "04456477780974006938"
     },
     "user_tz": -420
    },
    "id": "3mo0AIfg6iSP",
    "outputId": "4597954b-146d-4ca3-fc38-e0fbff0c4734"
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b4407e1f4fd5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfinal_spot_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspot_pos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "final_spot_dict = spot_pos[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwQxd25u6iSP"
   },
   "outputs": [],
   "source": [
    "print(len(final_spot_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "65d__V4H6iSP"
   },
   "outputs": [],
   "source": [
    "def assign_spots_map(image, spot_dict=final_spot_dict, make_copy = True, color=[255, 0, 0], thickness=2):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "    for spot in spot_dict.keys():\n",
    "        (x1, y1, x2, y2) = spot\n",
    "        cv2.rectangle(new_image, (int(x1),int(y1)), (int(x2),int(y2)), color, thickness)\n",
    "    return new_image\n",
    "\n",
    "marked_spot_images = list(map(assign_spots_map, test_images))\n",
    "show_images(marked_spot_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80s_adZhOoZK"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from google.colab import drive\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Path lengkap ke file di Google Drive\n",
    "file_path = '/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/spot_dict.pickle'\n",
    "\n",
    "# Simpan dictionary ke file pickle\n",
    "with open(file_path, 'wb') as handle:\n",
    "    pickle.dump(final_spot_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XtuOlZov6iSQ"
   },
   "outputs": [],
   "source": [
    "### Save spot dictionary as pickle file\n",
    "import pickle\n",
    "\n",
    "with open('spot_dict.pickle', 'wb') as handle:\n",
    "    pickle.dump(final_spot_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMZ3Ar2v6iSQ"
   },
   "source": [
    "### Save image for CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eumFNX9rXvk0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "   # Path ke folder di Google Drive\n",
    "folder_path = '/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/for_cnn'  # Ganti 'MyDrive' dengan folder tujuan di Drive kamu\n",
    "\n",
    "   # Buat folder jika belum ada\n",
    "if not os.path.exists(folder_path):\n",
    "       os.makedirs(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BPwFcUbW6iSQ"
   },
   "outputs": [],
   "source": [
    "def save_images_for_cnn(image, spot_dict=final_spot_dict, folder_name='for_cnn'):\n",
    "    for spot in spot_dict.keys():\n",
    "        (x1, y1, x2, y2) = spot\n",
    "        (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2))\n",
    "        # crop this image\n",
    "        spot_img = image[y1:y2, x1:x2]\n",
    "        spot_img = cv2.resize(spot_img, (0, 0), fx=2.0, fy=2.0)\n",
    "        spot_id = spot_dict[spot]\n",
    "\n",
    "        filename = 'spot' + str(spot_id) + '.jpg'\n",
    "        print(spot_img.shape, filename, (x1, x2, y1, y2))\n",
    "\n",
    "        # Simpan gambar ke folder 'for_cnn'\n",
    "        cv2.imwrite(os.path.join(folder_name, filename), spot_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SnTPNV5BX30R"
   },
   "outputs": [],
   "source": [
    "# ... (kode sebelumnya)\n",
    "marked_spot_images = list(map(assign_spots_map, test_images))\n",
    "show_images(marked_spot_images)\n",
    "\n",
    "# Panggil fungsi save_images_for_cnn di sini\n",
    "for image in test_images:\n",
    "    save_images_for_cnn(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gvkhFS8TYJFh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Cetak path lengkap ke folder\n",
    "print(os.path.abspath('for_cnn'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7lFBjlET70D"
   },
   "source": [
    "## mulai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2H1Lr3GEUMPy"
   },
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C4sU-MNxT-5q"
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "import os\n",
    "# Import from tensorflow.keras instead of keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras import backend as k\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8hLAXRHdUZvM"
   },
   "outputs": [],
   "source": [
    "files_train = 0\n",
    "files_validation = 0\n",
    "\n",
    "cwd = os.getcwd()\n",
    "folder = '/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/train'\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_train += len(files)\n",
    "\n",
    "\n",
    "folder = '/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/test'\n",
    "for sub_folder in os.listdir(folder):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder,sub_folder)))\n",
    "    files_validation += len(files)\n",
    "\n",
    "print(files_train,files_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lXfRBpyoVLLx"
   },
   "source": [
    "# tetapkan parameter utama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NAbJq5GrVOKl"
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 48, 48\n",
    "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/train\"\n",
    "validation_data_dir = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/test\"\n",
    "nb_train_samples = files_train\n",
    "nb_validation_samples = files_validation\n",
    "batch_size = 32\n",
    "epochs = 15\n",
    "num_classes = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S5gdP5BGVoUY"
   },
   "source": [
    "# Bangun model di atas VGG terlatih"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0uQ1bVcaVqKZ"
   },
   "outputs": [],
   "source": [
    "model = applications.VGG16(weights = \"imagenet\", include_top=False, input_shape = (img_width, img_height, 3))\n",
    "# Freeze the layers which you don't want to train. Here I am freezing the first 5 layers.\n",
    "for layer in model.layers[:10]:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GXpUaFNRVzHw"
   },
   "outputs": [],
   "source": [
    "# ... (kode sebelumnya di sel ipython-input-53-8a42504ea456)\n",
    "\n",
    "# Tambahkan baris ini setelah memuat model VGG16\n",
    "x = model.output\n",
    "x = Flatten()(x)  # Ratakan output\n",
    "x = Dense(num_classes, activation='softmax')(x)  # Tambahkan layer Dense dengan aktivasi softmax\n",
    "\n",
    "# Buat model baru\n",
    "model = Model(inputs=model.input, outputs=x)\n",
    "\n",
    "# Kompilasi model setelah modifikasi  <-- Baris ini yang ditambahkan\n",
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=optimizers.SGD(learning_rate=0.0001, momentum=0.9),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# ... (sisa kode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t6QlBWDLWj16"
   },
   "outputs": [],
   "source": [
    "# Initiate the train and test generators with data Augumentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=5)\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "rescale = 1./255,\n",
    "horizontal_flip = True,\n",
    "fill_mode = \"nearest\",\n",
    "zoom_range = 0.1,\n",
    "width_shift_range = 0.1,\n",
    "height_shift_range=0.1,\n",
    "rotation_range=5)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "train_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "batch_size = batch_size,\n",
    "class_mode = \"categorical\")\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "validation_data_dir,\n",
    "target_size = (img_height, img_width),\n",
    "class_mode = \"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4f1UD2WVWooY"
   },
   "outputs": [],
   "source": [
    "# Save the model according to the conditions\n",
    "checkpoint = ModelCheckpoint(\"car1.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)  # Change 'period' to 'save_freq' and filepath to 'car1.keras'\n",
    "early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=10, verbose=1, mode='max') # Add mode='max' to EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dwpTB98bnJK"
   },
   "outputs": [],
   "source": [
    "### Start training!\n",
    "# The variable 'model_final' was not defined. Using 'model' instead, assuming it contains the compiled model\n",
    "history_object = model.fit( # Changed fit_generator to fit, as fit_generator is deprecated\n",
    "    train_generator,\n",
    "    steps_per_epoch = nb_train_samples // batch_size, # Added steps_per_epoch, required for fit\n",
    "    epochs = epochs,\n",
    "    validation_data = validation_generator,\n",
    "    validation_steps = nb_validation_samples // batch_size, # Added validation_steps, required for fit\n",
    "    callbacks = [checkpoint, early]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7XNLd2b8dguX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history_object.history.keys())\n",
    "\n",
    "# Plot akurasi\n",
    "plt.plot(history_object.history['accuracy'])\n",
    "plt.plot(history_object.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Tampilkan akurasi detail\n",
    "train_accuracy = history_object.history['accuracy'][-1]\n",
    "val_accuracy = history_object.history['val_accuracy'][-1]\n",
    "\n",
    "print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "print(f\"Validation Accuracy: {val_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aUsU5CxbCTRZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(history_object.history.keys())\n",
    "\n",
    "# Plot akurasi\n",
    "plt.plot(history_object.history['accuracy'])\n",
    "plt.plot(history_object.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# Tampilkan skor training dan validation di gambar\n",
    "train_accuracy = history_object.history['accuracy'][-1]\n",
    "val_accuracy = history_object.history['val_accuracy'][-1]\n",
    "plt.text(len(history_object.history['accuracy']) - 1, train_accuracy, f'Train: {train_accuracy:.2%}', ha='right', va='bottom')\n",
    "plt.text(len(history_object.history['val_accuracy']) - 1, val_accuracy, f'Val: {val_accuracy:.2%}', ha='right', va='bottom')\n",
    "\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Tampilkan akurasi detail (opsional, bisa dihapus jika sudah ditampilkan di gambar)\n",
    "# print(f\"Training Accuracy: {train_accuracy:.2%}\")\n",
    "# print(f\"Validation Accuracy: {val_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9wTEKOggdtcv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Tampilkan loss detail\n",
    "train_loss = history_object.history['loss'][-1]\n",
    "val_loss = history_object.history['val_loss'][-1]\n",
    "\n",
    "print(f\"Training Loss: {train_loss:.4f}\")\n",
    "print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Q-B3TzECxIA"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "\n",
    "# Tampilkan loss detail di dalam gambar\n",
    "train_loss = history_object.history['loss'][-1]\n",
    "val_loss = history_object.history['val_loss'][-1]\n",
    "plt.text(len(history_object.history['loss']) - 1, train_loss, f'Train: {train_loss:.4f}', ha='right', va='bottom')\n",
    "plt.text(len(history_object.history['val_loss']) - 1, val_loss, f'Val: {val_loss:.4f}', ha='right', va='bottom')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Tampilkan loss detail (opsional, bisa dihapus jika sudah ditampilkan di gambar)\n",
    "#print(f\"Training Loss: {train_loss:.4f}\")\n",
    "#print(f\"Validation Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8LPRKGURewus"
   },
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(\"car1.keras\", monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', save_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEmRUx4hewtN"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "import os\n",
    "\n",
    "# Get the absolute path of the file\n",
    "file_path = os.path.abspath('car1.keras')  # Assuming car1.keras is in the current directory\n",
    "\n",
    "# Check if the file exists\n",
    "if os.path.exists(file_path):\n",
    "  files.download(file_path)\n",
    "else:\n",
    "  print(f\"Error: File not found at {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bC90q3a4h24J"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "print(os.getcwd()) # Menampilkan direktori kerja saat ini\n",
    "print(os.listdir()) # Menampilkan isi direktori kerja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4wM8NEwrh-Fk"
   },
   "outputs": [],
   "source": [
    "model.save('car1.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrrGjPg9P51A"
   },
   "source": [
    "## Evaluasi Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXJTbS9sOwt-"
   },
   "outputs": [],
   "source": [
    "# Import library yang dibutuhkan\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Load model yang sudah dilatih\n",
    "model = load_model('car1.keras') # Ganti dengan path model Anda\n",
    "\n",
    "# Load data test\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Jangan acak data untuk evaluasi\n",
    ")\n",
    "\n",
    "# Prediksi pada data test\n",
    "Y_pred = model.predict(validation_generator, nb_validation_samples // batch_size + 1)  # Prediksi menggunakan model\n",
    "y_pred = np.argmax(Y_pred, axis=1)  # Dapatkan kelas yang diprediksi\n",
    "y_true = validation_generator.classes  # Dapatkan label sebenarnya\n",
    "\n",
    "\n",
    "# Evaluasi model\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_true, y_pred))  # Menampilkan confusion matrix\n",
    "\n",
    "print('Classification Report')\n",
    "target_names = ['empty', 'occupied']  # Nama kelas\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))  # Menampilkan laporan klasifikasi\n",
    "\n",
    "# Hitung metrik evaluasi\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall = recall_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaPtKPUnPQI_"
   },
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Akurasi: {accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_EAS81zyPg4Y"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Membuat dan menampilkan confusion matrix dalam bentuk tabel\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "cm_df = pd.DataFrame(cm, index=['empty', 'occupied'], columns=['empty', 'occupied'])\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Njjmhj1PxMR"
   },
   "outputs": [],
   "source": [
    "# Membuat dan menampilkan confusion matrix dalam bentuk gambar\n",
    "import seaborn as sns\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['empty', 'occupied'],\n",
    "            yticklabels=['empty', 'occupied'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_0S5YPBm6iSQ"
   },
   "outputs": [],
   "source": [
    "## Imports for making predictions\n",
    "from PIL import Image\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iWOiqr3a6iSQ"
   },
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "top_model_weights_path = '/content/car1.keras'\n",
    "\n",
    "class_dictionary = {}\n",
    "class_dictionary[0] = 'empty'\n",
    "class_dictionary[1] = 'occupied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HMkkuVpf6iSQ"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "model = load_model(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eD2EMtyJ6iSQ"
   },
   "outputs": [],
   "source": [
    "def make_prediction(image):\n",
    "    #Rescale image\n",
    "    img = image/255.\n",
    "\n",
    "    #Convert to a 4D tensor\n",
    "    image = np.expand_dims(img, axis=0)\n",
    "    #print(image.shape)\n",
    "\n",
    "    # make predictions on the preloaded model\n",
    "    class_predicted = model.predict(image)\n",
    "    inID = np.argmax(class_predicted[0])\n",
    "    label = class_dictionary[inID]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s-Be_0_R6iSQ"
   },
   "outputs": [],
   "source": [
    "def predict_on_image(image, spot_dict = final_spot_dict, make_copy=True, color = [0, 255, 0], alpha=0.5):\n",
    "    if make_copy:\n",
    "        new_image = np.copy(image)\n",
    "        overlay = np.copy(image)\n",
    "    cnt_empty = 0\n",
    "    all_spots = 0\n",
    "    for spot in spot_dict.keys():\n",
    "        all_spots += 1\n",
    "        (x1, y1, x2, y2) = spot\n",
    "        (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2))\n",
    "        #crop this image\n",
    "        spot_img = image[y1:y2, x1:x2]\n",
    "        spot_img = cv2.resize(spot_img, (48, 48))\n",
    "\n",
    "        label = make_prediction(spot_img)\n",
    "#         print(label)\n",
    "        if label == 'empty':\n",
    "            cv2.rectangle(overlay, (int(x1),int(y1)), (int(x2),int(y2)), color, -1)\n",
    "            cnt_empty += 1\n",
    "\n",
    "    cv2.addWeighted(overlay, alpha, new_image, 1 - alpha, 0, new_image)\n",
    "\n",
    "    cv2.putText(new_image, \"Available: %d spots\" %cnt_empty, (30, 95),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    0.7, (255, 255, 255), 2)\n",
    "\n",
    "    cv2.putText(new_image, \"Total: %d spots\" %all_spots, (30, 125),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX,\n",
    "    0.7, (255, 255, 255), 2)\n",
    "    save = False\n",
    "\n",
    "    if save:\n",
    "        filename = 'with_marking.jpg'\n",
    "        cv2.imwrite(filename, new_image)\n",
    "\n",
    "    return new_image\n",
    "\n",
    "\n",
    "predicted_images = list(map(predict_on_image, test_images))\n",
    "show_images(predicted_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n7WUI1AI5Jc0"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Hitung jumlah data latih dan data uji\n",
    "files_train = 0\n",
    "files_validation = 0\n",
    "\n",
    "folder_train = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/train\"\n",
    "for sub_folder in os.listdir(folder_train):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder_train, sub_folder)))\n",
    "    files_train += len(files)\n",
    "\n",
    "folder_test = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/test\"\n",
    "for sub_folder in os.listdir(folder_test):\n",
    "    path, dirs, files = next(os.walk(os.path.join(folder_test, sub_folder)))\n",
    "    files_validation += len(files)\n",
    "\n",
    "# Data untuk grafik\n",
    "categories = ['Train Data', 'Test Data']\n",
    "values = [files_train, files_validation]\n",
    "\n",
    "# Membuat grafik batang\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.bar(categories, values, color=['blue', 'orange'])\n",
    "plt.title('Jumlah Data Latih dan Data Uji')\n",
    "plt.xlabel('Kategori Data')\n",
    "plt.ylabel('Jumlah Data')\n",
    "\n",
    "# Menambahkan label nilai di atas setiap batang\n",
    "for i, v in enumerate(values):\n",
    "    plt.text(i, v + 5, str(v), ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ruxdt_1_hXn"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def hitung_total_data(folder_path):\n",
    "    total_count = 0\n",
    "    for sub_folder in os.listdir(folder_path):\n",
    "        path, dirs, files = next(os.walk(os.path.join(folder_path, sub_folder)))\n",
    "        total_count += len(files)\n",
    "    return total_count\n",
    "\n",
    "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/train\"\n",
    "validation_data_dir = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/test\"\n",
    "\n",
    "total_train_data = hitung_total_data(train_data_dir)\n",
    "total_test_data = hitung_total_data(validation_data_dir)\n",
    "\n",
    "total_data = total_train_data + total_test_data\n",
    "\n",
    "print(\"Total Data Latih:\", total_train_data)\n",
    "print(\"Total Data Uji:\", total_test_data)\n",
    "print(\"Total Data:\", total_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aZl0y4yc_w8Q"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def hitung_distribusi_kelas(folder_path):\n",
    "    empty_count = len(os.listdir(os.path.join(folder_path, 'empty')))\n",
    "    occupied_count = len(os.listdir(os.path.join(folder_path, 'occupied')))\n",
    "    return empty_count, occupied_count\n",
    "\n",
    "train_empty_count, train_occupied_count = hitung_distribusi_kelas(train_data_dir)\n",
    "test_empty_count, test_occupied_count = hitung_distribusi_kelas(validation_data_dir)\n",
    "\n",
    "print(\"Data Latih:\")\n",
    "print(\"Kosong:\", train_empty_count)\n",
    "print(\"Terisi:\", train_occupied_count)\n",
    "\n",
    "print(\"\\nData Uji:\")\n",
    "print(\"Kosong:\", test_empty_count)\n",
    "print(\"Terisi:\", test_occupied_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W6BmLbnlADPw"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Data distribusi kelas (dari kode Anda sebelumnya)\n",
    "train_empty_count, train_occupied_count = hitung_distribusi_kelas(train_data_dir)\n",
    "test_empty_count, test_occupied_count = hitung_distribusi_kelas(validation_data_dir)\n",
    "\n",
    "# Data untuk grafik\n",
    "categories = ['Kosong', 'Terisi']\n",
    "train_values = [train_empty_count, train_occupied_count]\n",
    "test_values = [test_empty_count, test_occupied_count]\n",
    "\n",
    "# Membuat grafik batang dengan ukuran kecil\n",
    "fig, ax = plt.subplots(figsize=(4, 3))  # Mengatur ukuran grafik (lebar, tinggi)\n",
    "\n",
    "bar_width = 0.35  # Lebar setiap batang\n",
    "index = np.arange(len(categories))\n",
    "\n",
    "rects1 = ax.bar(index, train_values, bar_width, label='Data Latih', color='blue')\n",
    "rects2 = ax.bar(index + bar_width, test_values, bar_width, label='Data Uji', color='orange')\n",
    "\n",
    "# Menambahkan label, judul, dan legenda\n",
    "ax.set_xlabel('Kelas')\n",
    "ax.set_ylabel('Jumlah Gambar')\n",
    "ax.set_title('Distribusi Kelas Data Latih dan Data Uji', fontsize=10)  # Mengatur ukuran font judul\n",
    "ax.set_xticks(index + bar_width / 2)\n",
    "ax.set_xticklabels(categories)\n",
    "ax.legend(fontsize=8)  # Mengatur ukuran font legenda\n",
    "\n",
    "# Menambahkan label nilai di atas setiap batang\n",
    "def autolabel(rects):\n",
    "    for rect in rects:\n",
    "        height = rect.get_height()\n",
    "        ax.text(rect.get_x() + rect.get_width() / 2, height,\n",
    "                '%d' % int(height), ha='center', va='bottom', fontsize=8)  # Mengatur ukuran font label nilai\n",
    "\n",
    "autolabel(rects1)\n",
    "autolabel(rects2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bb8f51BEAZmX"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Path ke folder data latih\n",
    "train_data_dir = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/train_data/train\"\n",
    "\n",
    "# Mendapatkan path ke gambar contoh\n",
    "empty_image_path = os.path.join(train_data_dir, 'empty', os.listdir(os.path.join(train_data_dir, 'empty'))[0])  # Path gambar kosong pertama\n",
    "occupied_image_path = os.path.join(train_data_dir, 'occupied', os.listdir(os.path.join(train_data_dir, 'occupied'))[0])  # Path gambar terisi pertama\n",
    "\n",
    "\n",
    "# Membaca dan menampilkan gambar\n",
    "img_empty = cv2.imread(empty_image_path)\n",
    "img_occupied = cv2.imread(occupied_image_path)\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(cv2.cvtColor(img_empty, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Contoh Tempat Parkir Kosong')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(cv2.cvtColor(img_occupied, cv2.COLOR_BGR2RGB))\n",
    "plt.title('Contoh Tempat Parkir Terisi')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNFTjeC46iSQ"
   },
   "source": [
    "### Run code on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6y3ZiictQ4v2"
   },
   "outputs": [],
   "source": [
    "pip install streamlit opencv-python pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ofR76A9qSGPu"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T4QgzA-CSJiZ"
   },
   "outputs": [],
   "source": [
    "!pip install opencv-python-headless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XOT0HP8dyru9"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Path ke file video\n",
    "video_path = \"/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/parking_video.mp4\"\n",
    "\n",
    "# Membuka video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Tidak dapat membuka video.\")\n",
    "else:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Contoh proses frame: ubah ke grayscale\n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Print ukuran frame (sebagai contoh, tidak ditampilkan langsung)\n",
    "        print(f\"Frame size: {gray_frame.shape}\")\n",
    "\n",
    "cap.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "laWtR_bRzAQK"
   },
   "outputs": [],
   "source": [
    "# Tentukan codec dan buat VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('output_video.mp4', fourcc, 30.0, (640, 480))\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Proses frame jika diperlukan (misalnya, tambahkan filter atau deteksi objek)\n",
    "    out.write(frame)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d6Ys4Pc1zGAU"
   },
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from IPython.display import Video\n",
    "\n",
    "# Tampilkan video dalam format HTML\n",
    "HTML(\"\"\"\n",
    "<video width=600 controls>\n",
    "    <source src=\"output_video.mp4\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "G3UM2xPNzUIi"
   },
   "outputs": [],
   "source": [
    "Video('output_video.mp4', embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyZVdl2VYfgg"
   },
   "outputs": [],
   "source": [
    "from google.colab.patches import cv2_imshow\n",
    "video_name = '/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/parking_video.mp4'\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "ret = True\n",
    "count = 0\n",
    "\n",
    "while ret:\n",
    "        ret, image = cap.read()\n",
    "        count += 1\n",
    "        if count == 5:\n",
    "            count = 0\n",
    "\n",
    "            new_image = np.copy(image)\n",
    "            overlay = np.copy(image)\n",
    "            cnt_empty = 0\n",
    "            all_spots = 0\n",
    "            color = [0, 255, 0]\n",
    "            alpha=0.5\n",
    "            for spot in final_spot_dict.keys():\n",
    "                all_spots += 1\n",
    "                (x1, y1, x2, y2) = spot\n",
    "                (x1, y1, x2, y2) = (int(x1), int(y1), int(x2), int(y2))\n",
    "                #crop this image\n",
    "                spot_img = image[y1:y2, x1:x2]\n",
    "                spot_img = cv2.resize(spot_img, (48, 48))\n",
    "\n",
    "                label = make_prediction(spot_img)\n",
    "        #         print(label)\n",
    "                if label == 'empty':\n",
    "                    cv2.rectangle(overlay, (int(x1),int(y1)), (int(x2),int(y2)), color, -1)\n",
    "                    cnt_empty += 1\n",
    "\n",
    "            cv2.addWeighted(overlay, alpha, new_image, 1 - alpha, 0, new_image)\n",
    "\n",
    "            cv2.putText(new_image, \"Available: %d spots\" %cnt_empty, (30, 95),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7, (255, 255, 255), 2)\n",
    "\n",
    "            cv2.putText(new_image, \"Total: %d spots\" %all_spots, (30, 125),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.7, (255, 255, 255), 2)\n",
    "            cv2.imshow('frame', new_image)\n",
    "            if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "                break\n",
    "        #out.write(image)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dqmowr0zmdEf"
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "from PIL import Image\n",
    "\n",
    "video_name = '/content/drive/MyDrive/Colab Notebooks/parking_spots_detector/parking_video.mp4'\n",
    "cap = cv2.VideoCapture(video_name)\n",
    "ret = True\n",
    "\n",
    "# FPS adjustment\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "delay = int(1000 / fps)\n",
    "\n",
    "while ret:\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        # Convert frame to RGB for PIL.Image\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(frame_rgb)\n",
    "\n",
    "        # Prediksi dan gambar kotak\n",
    "        predicted_frame = predict_on_image(frame, final_spot_dict, make_copy=True)\n",
    "        predicted_rgb = cv2.cvtColor(predicted_frame, cv2.COLOR_BGR2RGB)\n",
    "        predicted_image = Image.fromarray(predicted_rgb)\n",
    "\n",
    "        # Tampilkan frame\n",
    "        clear_output(wait=True)\n",
    "        display(predicted_image)\n",
    "\n",
    "        # Tunggu beberapa saat sebelum menampilkan frame berikutnya\n",
    "        # cv2.waitKey(delay)  # Diperlukan jika menggunakan cv2.imshow()\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iAqUDqSSmdDL"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
